{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I simply changed the Cross Entropy by BCE with logit loss\n",
    "\n",
    "This allows for multi-class. However, may not be ideal for predicting uncommon classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGIONS_BUCKETS = {'europe': ['europe','denmark-1','denmark-2'],\n",
    "                   'east-africa':['east-africa','tanzania-1','tanzania-2','tanzania-3','tanzania-4','tanzania-5','uganda-1'],\n",
    "                   'northwest-africa':['eq-guinea','ghana-1','egypt-1','isreal-1','isreal-2','nigeria','senegal'],\n",
    "                   'north-america':['north-america'],\n",
    "                   'south-america':['south-america'],\n",
    "                   'japan':['japan']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_folder = \"/home/ccollado/phileo_phisat2/L1C/np_patches_128_cropped\"\n",
    "train_files = [f for f in os.listdir(patches_folder) if f.endswith(\"train_label_lc.npy\")]\n",
    "europe_train_files = [f for f in train_files if any([region in f for region in REGIONS_BUCKETS['europe']])]\n",
    "unique_keys = [10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing region: europe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [00:00<00:00, 260.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing region: east-africa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:07<00:00, 29.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing region: northwest-africa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 355/355 [00:07<00:00, 49.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing region: north-america\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:01<00:00, 42.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing region: south-america\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 40.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing region: japan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:00<00:00, 51.06it/s]\n"
     ]
    }
   ],
   "source": [
    "df_counts = pd.DataFrame(index=unique_keys, columns=REGIONS_BUCKETS.keys(), data=0.0)\n",
    "df_proportions = df_counts.copy()\n",
    "\n",
    "for region, region_files in REGIONS_BUCKETS.items():\n",
    "    print(f\"Processing region: {region}\")\n",
    "    # Filter train files for the current region\n",
    "    region_train_files = [f for f in train_files if any([region in f for region in region_files])]\n",
    "    num_files = 0\n",
    "\n",
    "    # Process each file in the current region\n",
    "    for file in tqdm(region_train_files):\n",
    "        arr = np.load(os.path.join(patches_folder, file))\n",
    "        num_files += arr.shape[0]\n",
    "        present_keys = [sum(1 for i in range(arr.shape[0]) if key in arr[i]) for key in unique_keys]\n",
    "        df_counts.loc[:, region] += present_keys\n",
    "\n",
    "    df_proportions.loc[:, region] = df_counts.loc[:, region] / num_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>europe</th>\n",
       "      <th>east-africa</th>\n",
       "      <th>northwest-africa</th>\n",
       "      <th>north-america</th>\n",
       "      <th>south-america</th>\n",
       "      <th>japan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.746012</td>\n",
       "      <td>0.854841</td>\n",
       "      <td>0.655800</td>\n",
       "      <td>0.838482</td>\n",
       "      <td>0.873825</td>\n",
       "      <td>0.851811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.017207</td>\n",
       "      <td>0.917982</td>\n",
       "      <td>0.811546</td>\n",
       "      <td>0.171274</td>\n",
       "      <td>0.316348</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.813587</td>\n",
       "      <td>0.933373</td>\n",
       "      <td>0.913679</td>\n",
       "      <td>0.813550</td>\n",
       "      <td>0.814983</td>\n",
       "      <td>0.608123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.541674</td>\n",
       "      <td>0.828927</td>\n",
       "      <td>0.689375</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.219594</td>\n",
       "      <td>0.504940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.501882</td>\n",
       "      <td>0.578269</td>\n",
       "      <td>0.334777</td>\n",
       "      <td>0.530623</td>\n",
       "      <td>0.370337</td>\n",
       "      <td>0.407245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.124574</td>\n",
       "      <td>0.227901</td>\n",
       "      <td>0.226687</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.282681</td>\n",
       "      <td>0.198683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.020792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.415487</td>\n",
       "      <td>0.046961</td>\n",
       "      <td>0.090978</td>\n",
       "      <td>0.256911</td>\n",
       "      <td>0.265999</td>\n",
       "      <td>0.254665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.165442</td>\n",
       "      <td>0.075901</td>\n",
       "      <td>0.078306</td>\n",
       "      <td>0.076965</td>\n",
       "      <td>0.113436</td>\n",
       "      <td>0.037322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.011372</td>\n",
       "      <td>0.021680</td>\n",
       "      <td>0.020322</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.064169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       europe  east-africa  northwest-africa  north-america  south-america  \\\n",
       "10   0.746012     0.854841          0.655800       0.838482       0.873825   \n",
       "20   0.017207     0.917982          0.811546       0.171274       0.316348   \n",
       "30   0.813587     0.933373          0.913679       0.813550       0.814983   \n",
       "40   0.541674     0.828927          0.689375       0.222222       0.219594   \n",
       "50   0.501882     0.578269          0.334777       0.530623       0.370337   \n",
       "60   0.124574     0.227901          0.226687       0.406504       0.282681   \n",
       "70   0.020792     0.000000          0.000000       0.000000       0.000000   \n",
       "80   0.415487     0.046961          0.090978       0.256911       0.265999   \n",
       "90   0.165442     0.075901          0.078306       0.076965       0.113436   \n",
       "95   0.000000     0.000855          0.011372       0.021680       0.020322   \n",
       "100  0.064169     0.000000          0.000000       0.000000       0.000000   \n",
       "\n",
       "        japan  \n",
       "10   0.851811  \n",
       "20   0.000000  \n",
       "30   0.608123  \n",
       "40   0.504940  \n",
       "50   0.407245  \n",
       "60   0.198683  \n",
       "70   0.000000  \n",
       "80   0.254665  \n",
       "90   0.037322  \n",
       "95   0.000000  \n",
       "100  0.000000  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts.to_csv(\"counts_by_region.csv\")\n",
    "df_proportions.to_csv(\"proportions_by_region.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10     70550.0\n",
       "20      1443.0\n",
       "30     76088.0\n",
       "40     49178.0\n",
       "50     42043.0\n",
       "60      9539.0\n",
       "70      1844.0\n",
       "80     52736.0\n",
       "90     14297.0\n",
       "95         0.0\n",
       "100     6897.0\n",
       "Name: europe, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_counts = pd.read_csv(\"counts_by_region.csv\", index_col=0)\n",
    "df_counts['europe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>europe</th>\n",
       "      <th>east-africa</th>\n",
       "      <th>northwest-africa</th>\n",
       "      <th>north-america</th>\n",
       "      <th>south-america</th>\n",
       "      <th>japan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.648855</td>\n",
       "      <td>0.804432</td>\n",
       "      <td>0.557173</td>\n",
       "      <td>0.730714</td>\n",
       "      <td>0.820688</td>\n",
       "      <td>0.626112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.013271</td>\n",
       "      <td>0.878918</td>\n",
       "      <td>0.748600</td>\n",
       "      <td>0.232399</td>\n",
       "      <td>0.269052</td>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.699788</td>\n",
       "      <td>0.880432</td>\n",
       "      <td>0.845139</td>\n",
       "      <td>0.730013</td>\n",
       "      <td>0.731161</td>\n",
       "      <td>0.365443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.452295</td>\n",
       "      <td>0.715842</td>\n",
       "      <td>0.673682</td>\n",
       "      <td>0.228498</td>\n",
       "      <td>0.180196</td>\n",
       "      <td>0.247172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.386673</td>\n",
       "      <td>0.379115</td>\n",
       "      <td>0.241348</td>\n",
       "      <td>0.351259</td>\n",
       "      <td>0.221172</td>\n",
       "      <td>0.147640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.087731</td>\n",
       "      <td>0.125112</td>\n",
       "      <td>0.176797</td>\n",
       "      <td>0.313710</td>\n",
       "      <td>0.163098</td>\n",
       "      <td>0.068165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.016959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.485018</td>\n",
       "      <td>0.071864</td>\n",
       "      <td>0.111725</td>\n",
       "      <td>0.282712</td>\n",
       "      <td>0.254164</td>\n",
       "      <td>0.419281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.131491</td>\n",
       "      <td>0.076411</td>\n",
       "      <td>0.055611</td>\n",
       "      <td>0.077542</td>\n",
       "      <td>0.092940</td>\n",
       "      <td>0.011688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.017466</td>\n",
       "      <td>0.017497</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.063432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       europe  east-africa  northwest-africa  north-america  south-america  \\\n",
       "10   0.648855     0.804432          0.557173       0.730714       0.820688   \n",
       "20   0.013271     0.878918          0.748600       0.232399       0.269052   \n",
       "30   0.699788     0.880432          0.845139       0.730013       0.731161   \n",
       "40   0.452295     0.715842          0.673682       0.228498       0.180196   \n",
       "50   0.386673     0.379115          0.241348       0.351259       0.221172   \n",
       "60   0.087731     0.125112          0.176797       0.313710       0.163098   \n",
       "70   0.016959     0.000000          0.000000       0.000000       0.000000   \n",
       "80   0.485018     0.071864          0.111725       0.282712       0.254164   \n",
       "90   0.131491     0.076411          0.055611       0.077542       0.092940   \n",
       "95   0.000000     0.001152          0.017466       0.017497       0.018911   \n",
       "100  0.063432     0.000000          0.000000       0.002859       0.000000   \n",
       "\n",
       "        japan  \n",
       "10   0.626112  \n",
       "20   0.000113  \n",
       "30   0.365443  \n",
       "40   0.247172  \n",
       "50   0.147640  \n",
       "60   0.068165  \n",
       "70   0.000000  \n",
       "80   0.419281  \n",
       "90   0.011688  \n",
       "95   0.000075  \n",
       "100  0.000038  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proportions = pd.read_csv(\"proportions_by_region.csv\", index_col=0)\n",
    "df_proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML-ROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Author  : Light--\n",
    "\n",
    "\"\"\"\n",
    "Description：use ml-ros to balance celeba train set\n",
    "Similar repo: https://github.com/wtomin/Multitask-Emotion-Recognition-with-Incomplete-Labels/blob/0cedf4ca8e117fe5f2950d58af67c1e4cc831f95/create_annotation_file/DISFA/create_annotation_Mixed_AU.py\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def IRLbl(labels):\n",
    "    # imbalance ratio per label\n",
    "    # Args:\n",
    "    #\t labels is a 2d numpy array, each row is one instance, each column is one class; the array contains (0, 1) only\n",
    "    N, C = labels.shape\n",
    "    pos_nums_per_label = np.sum(labels, axis=0)\n",
    "    max_pos_nums = np.max(pos_nums_per_label)\n",
    "    return max_pos_nums / pos_nums_per_label\n",
    "\n",
    "def MeanIR(labels):\n",
    "    IRLbl_VALUE = IRLbl(labels)\n",
    "    return np.mean(IRLbl_VALUE)\n",
    "\n",
    "def ML_ROS(all_labels, indices=None, num_samples=None, Preset_MeanIR_value=2.,\n",
    "                 max_clone_percentage=50, sample_size=32):\n",
    "    # the index of samples: 0, 1, ....\n",
    "    # if indices is not provided,\n",
    "    # all elements in the dataset will be considered\n",
    "    indices = list(range(len(all_labels))) \\\n",
    "        if indices is None else indices\n",
    "\n",
    "    # if num_samples is not provided,\n",
    "    # draw `len(indices)` samples in each iteration\n",
    "    num_samples = len(indices) \\\n",
    "        if num_samples is None else num_samples\n",
    "\n",
    "    MeanIR_value = MeanIR(all_labels) if Preset_MeanIR_value == 0 else Preset_MeanIR_value\n",
    "    IRLbl_value = IRLbl(all_labels)\n",
    "    # N is the number of samples, C is the number of labels\n",
    "    N, C = all_labels.shape\n",
    "    # the samples index of every class\n",
    "    indices_per_class = {}\n",
    "    minority_classes = []\n",
    "    # accroding to psedu code, maxSamplesToClone is the upper limit of the number of samples can be copied from original dataset\n",
    "    maxSamplesToClone = N / 100 * max_clone_percentage\n",
    "    print('Max Clone Limit:', maxSamplesToClone)\n",
    "    for i in range(C):\n",
    "        ids = all_labels[:, i] == 1\n",
    "        # How many samples are there for each label\n",
    "        indices_per_class[i] = [ii for ii, x in enumerate(ids) if x]\n",
    "        if IRLbl_value[i] > MeanIR_value:\n",
    "            minority_classes.append(i)\n",
    "\n",
    "    new_all_labels = all_labels\n",
    "    oversampled_ids = []\n",
    "    minorNum = len(minority_classes)\n",
    "    print(minorNum, 'minor classes.')\n",
    "\n",
    "    for idx, i in enumerate(minority_classes):\n",
    "        tid = time.time()\n",
    "        while True:\n",
    "            pick_id = list(np.random.choice(indices_per_class[i], sample_size))\n",
    "            indices_per_class[i].extend(pick_id)\n",
    "            # recalculate the IRLbl_value\n",
    "            # The original label matrix (New_ all_ Labels) and randomly selected label matrix (all_ labels[pick_ ID) and recalculate the irlbl\n",
    "            new_all_labels = np.concatenate([new_all_labels, all_labels[pick_id]], axis=0)\n",
    "            oversampled_ids.extend(pick_id)\n",
    "\n",
    "            newIrlbl = IRLbl(new_all_labels)\n",
    "            if newIrlbl[i] <= MeanIR_value:\n",
    "                print('\\nMeanIR satisfied.', newIrlbl[i])\n",
    "                break\n",
    "            if len(oversampled_ids) >= maxSamplesToClone:\n",
    "                print('\\nExceed max clone.', len(oversampled_ids))\n",
    "                break\n",
    "            # if IRLbl(new_all_labels)[i] <= MeanIR_value or len(oversampled_ids) >= maxSamplesToClone:\n",
    "            #     break\n",
    "            print(\"\\roversample length:{}\".format(len(oversampled_ids)), end='')\n",
    "        print('Processed the %d/%d minor class:' % (idx+1, minorNum), i, time.time()-tid, 's')\n",
    "        if len(oversampled_ids) >= maxSamplesToClone:\n",
    "            print('Exceed max clone. Exit', len(oversampled_ids))\n",
    "            break\n",
    "    return new_all_labels, oversampled_ids\n",
    "\n",
    "# get all sample labels from celeba txt annotation file \n",
    "def get_all_labels(root, annFile, ):\n",
    "    import os\n",
    "    targets = []\n",
    "    images = []\n",
    "\n",
    "    for line in open(os.path.join(root, annFile), 'r'):\n",
    "        sample = line.split()\n",
    "        # print(sample)\n",
    "        if len(sample) != 41:\n",
    "            raise (RuntimeError(\"# Annotated face attributes of CelebA dataset should not be different from 40\"))\n",
    "        images.append(sample[0])\n",
    "        # target = [int(i) for i in sample[1:]] # -1 label will cause error\n",
    "        target = [0 if int(i) == -1 else int(i) for i in sample[1:]]\n",
    "        targets.append(target)\n",
    "    targets = np.array(targets)\n",
    "    print('All labels in the dataset:', targets.shape)\n",
    "    return targets\n",
    "\n",
    "# Copy samples that need to be oversampled, according to new txt annotation file generated after ml-ros processed \n",
    "def copy_samples(root, annFile, newAnnFile, copyIds):\n",
    "    import os\n",
    "    from shutil import copyfile\n",
    "    import sys\n",
    "\n",
    "    # adding exception handling\n",
    "    srcFile = os.path.join(root, annFile)\n",
    "    dstFile = os.path.join(root, newAnnFile)\n",
    "    # copy original file to new file\n",
    "    try:\n",
    "        copyfile(srcFile, dstFile)\n",
    "    except IOError as e:\n",
    "        print(\"Unable to copy file. %s\" % e)\n",
    "        exit(1)\n",
    "    except:\n",
    "        print(\"Unexpected error:\", sys.exc_info())\n",
    "        exit(1)\n",
    "\n",
    "    # copy samples to new file\n",
    "    copied = 0\n",
    "    txt = np.loadtxt(srcFile, dtype=str)\n",
    "    copyNum = len(copyIds)\n",
    "    txt = txt.tolist()\n",
    "\n",
    "    for lineId in copyIds:\n",
    "        newAnnFile = open(dstFile, 'a')\n",
    "        line = txt[lineId]\n",
    "        line = ' '.join(line) + '\\n'\n",
    "        newAnnFile.write(line)\n",
    "        copied += 1\n",
    "        print('\\rCopied %d/%d' % (copied, copyNum), end='')\n",
    "    print('\\nUpsampling Done. ', dstFile)\n",
    "\n",
    "# use ml-ros to process celeba dataset, reduce the class imbalance\n",
    "# def mlros_celeba():\n",
    "#     celebaRoot = r'/data2/xxx/tmp_data/celeba_mlros/annot'\n",
    "#     annFile = 'train_40_att_list.txt'\n",
    "#     allLabels = get_all_labels(celebaRoot, annFile,)\n",
    "#     print('Origianl:', len(allLabels))\n",
    "#     t1 = time.time()\n",
    "#     newLables, oversampleIds = ML_ROS(allLabels, )\n",
    "#     print('New:', len(newLables), time.time()-t1, 's')\n",
    "#     # generate new train.txt\n",
    "#     newAnnFile = 'mlros_' + annFile\n",
    "#     copy_samples(celebaRoot, annFile, newAnnFile, oversampleIds)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     mlros_celeba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing region: europe\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(y, class_labels=np.array([10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 100])):\n",
    "    y_classification = np.isin(class_labels, y).astype(np.float32)\n",
    "    return y_classification\n",
    "for region, region_files in REGIONS_BUCKETS.items():\n",
    "    print(f\"Processing region: {region}\")\n",
    "    # Filter train files for the current region\n",
    "    region_train_files = [f for f in train_files if any([region in f for region in region_files])]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:13<00:00, 13.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(108730, 11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot_encoded_list = []\n",
    "\n",
    "for file in tqdm(region_train_files):\n",
    "    train_file = np.load(os.path.join(patches_folder, file))\n",
    "    hot_encoded = np.array([to_one_hot(train_file[i]) for i in range(train_file.shape[0])])\n",
    "    hot_encoded_list.append(hot_encoded)\n",
    "\n",
    "# Concatenate all hot_encoded arrays\n",
    "extended_hot_encoded = np.concatenate(hot_encoded_list, axis=0)\n",
    "extended_hot_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3509152/4193040695.py:18: RuntimeWarning: divide by zero encountered in divide\n",
      "  return max_pos_nums / pos_nums_per_label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Clone Limit: 54365.0\n",
      "6 minor classes.\n",
      "oversample length:54336\n",
      "Exceed max clone. 54368\n",
      "Processed the 1/6 minor class: 1 9.052268505096436 s\n",
      "Exceed max clone. Exit 54368\n"
     ]
    }
   ],
   "source": [
    "new_labels, oversampled_ids = ML_ROS(extended_hot_encoded, num_samples=1000, max_clone_percentage=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54368"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oversampled_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML-RUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples per class before:\n",
      "[0.053 0.105 0.245 0.274 0.334 0.035 0.13  0.027 0.175 0.31  0.307]\n",
      "Number of samples to keep:\n",
      "250\n",
      "Positive samples per class after keeping:\n",
      "[0.172 0.244 0.452 0.48  0.496 0.124 0.292 0.108 0.364 0.456 0.512]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import random\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "\n",
    "def distribute_remainder(r, r_dist, idx):\n",
    "    p = len(r_dist) - idx + 1\n",
    "    value = r // p\n",
    "    curr_rem = r % p\n",
    "\n",
    "    r_dist[idx:] = np.add(r_dist[idx:], value)\n",
    "    \n",
    "    if curr_rem > 0:\n",
    "        start = len(r_dist) - curr_rem\n",
    "        r_dist[start:] = np.add(r_dist[start:], 1)\n",
    "\n",
    "\n",
    "def LP_RUS(y, samples_to_keep):\n",
    "    total_samples = y.shape[0]\n",
    "    samples_to_delete = total_samples - samples_to_keep\n",
    "    if samples_to_delete <= 0:\n",
    "        return list(range(total_samples))\n",
    "\n",
    "    lp = LabelPowerset()\n",
    "    labelsets = np.array(lp.transform(y))\n",
    "    label_set_bags = defaultdict(list)\n",
    "    for idx, label in enumerate(labelsets):\n",
    "        label_set_bags[label].append(idx)\n",
    "\n",
    "    # Sort label sets by size descending\n",
    "    sorted_labels = sorted(label_set_bags.keys(), key=lambda l: len(label_set_bags[l]), reverse=True)\n",
    "\n",
    "    del_samples = []\n",
    "    # Iteratively remove samples from the largest sets until we've deleted exactly samples_to_delete\n",
    "    for label in sorted_labels:\n",
    "        if len(del_samples) == samples_to_delete:\n",
    "            break\n",
    "        # How many can we remove from this label without going below 0\n",
    "        can_remove = min(len(label_set_bags[label]), samples_to_delete - len(del_samples))\n",
    "        # Remove \"can_remove\" samples (no heuristic, just remove from front or randomly)\n",
    "        for _ in range(can_remove):\n",
    "            del_samples.append(label_set_bags[label].pop())\n",
    "\n",
    "    # If we haven't reached the exact deletion count for some reason, try again or adjust logic\n",
    "    # But if done carefully, it should match exactly.\n",
    "\n",
    "    all_indices = set(range(total_samples))\n",
    "    del_set = set(del_samples)\n",
    "    keep_indices = all_indices - del_set\n",
    "    return sorted(list(keep_indices))\n",
    "\n",
    "\n",
    "# Example of usage:\n",
    "x, y = make_multilabel_classification(n_samples=1000, n_features=10, n_classes=11)\n",
    "\n",
    "print('Positive samples per class before:')\n",
    "print(np.mean(y, axis=0))\n",
    "\n",
    "# Choose how many samples to keep, e.g., keep 750 samples out of 1000\n",
    "num_to_keep = 250\n",
    "keep_idxs = LP_RUS(y, num_to_keep)\n",
    "\n",
    "print('Number of samples to keep:')\n",
    "print(len(keep_idxs))\n",
    "\n",
    "print('Positive samples per class after keeping:')\n",
    "print(np.mean(y[keep_idxs, :], axis=0))\n",
    "\n",
    "# Plot the means before and after\n",
    "x_labels = [f'C{i+1}' for i in range(y.shape[1])]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharey=True)\n",
    "\n",
    "# Plot before\n",
    "axes[0].bar(x_labels, np.mean(y, axis=0))\n",
    "axes[0].set_title('Positive Samples per Class (Before)')\n",
    "axes[0].set_ylabel('Mean')\n",
    "axes[0].set_ylim(0, 1)\n",
    "\n",
    "# Plot after\n",
    "axes[1].bar(x_labels, np.mean(y[keep_idxs, :], axis=0), color='orange')\n",
    "axes[1].set_title('Positive Samples per Class (After)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Example: Assume `labels` is a 2D tensor with shape (num_samples, num_classes)\n",
    "# Each entry is 0 or 1, indicating the absence or presence of a label.\n",
    "labels = torch.tensor([[1, 0, 1], [0, 1, 0], [1, 1, 0], [0, 0, 1]])  # Example dataset\n",
    "\n",
    "# Count positive and negative samples per label\n",
    "num_samples = labels.size(0)\n",
    "pos_counts = labels.sum(dim=0)  # Number of positive samples for each label\n",
    "neg_counts = num_samples - pos_counts  # Number of negative samples for each label\n",
    "\n",
    "# Compute positive weights\n",
    "pos_weight = neg_counts / (pos_counts + 1e-8)  # Add epsilon to avoid division by zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phileo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
